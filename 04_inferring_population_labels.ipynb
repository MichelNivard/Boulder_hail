{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MichelNivard/Boulder_hail/blob/main/04_inferring_population_labels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bQ-_tvWtka5"
      },
      "source": [
        "# Institute for Behavioral Genetics International Statistical Genetics 2021 Workshop \n",
        "\n",
        "## Inferring Population Labels\n",
        "\n",
        "Learning objectives:\n",
        "\n",
        "1. Plot principal components obtained by running PCA on our dataset.\n",
        "2. Use principal components to identify population clusters.\n",
        "3. Reidentify populations for samples with missing populations using population clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8g_nE4wBtka8",
        "outputId": "f4e25004-9b2e-4525-a170-bebd95a074b7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div class=\"bk-root\">\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
              "        <span id=\"1001\">Loading BokehJS ...</span>\n",
              "    </div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(\"1001\");\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }\n",
              "\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "  };var element = document.getElementById(\"1001\");\n",
              "  if (element == null) {\n",
              "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
              "    return false;\n",
              "  }\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  \n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
              "  var css_urls = [];\n",
              "  \n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    function(Bokeh) {\n",
              "    \n",
              "    \n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if (root.Bokeh !== undefined || force === true) {\n",
              "      \n",
              "    for (var i = 0; i < inline_js.length; i++) {\n",
              "      inline_js[i].call(root, root.Bokeh);\n",
              "    }\n",
              "    if (force === true) {\n",
              "        display_loaded();\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(css_urls, js_urls, function() {\n",
              "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/03/10 08:04:56 WARN Utils: Your hostname, ip-10-0-201-238 resolves to a loopback address: 127.0.1.1; using 10.0.201.238 instead (on interface ens5)\n",
            "23/03/10 08:04:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
            "23/03/10 08:04:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23/03/10 08:04:56 WARN Hail: This Hail JAR was compiled for Spark 3.3.0, running with Spark 3.3.2.\n",
            "  Compatibility is not guaranteed.\n",
            "23/03/10 08:04:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Running on Apache Spark version 3.3.2\n",
            "SparkUI available at http://10.0.201.238:4041\n",
            "Welcome to\n",
            "     __  __     <>__\n",
            "    / /_/ /__  __/ /\n",
            "   / __  / _ `/ / /\n",
            "  /_/ /_/\\_,_/_/_/   version 0.2.109-b123465fc0bf\n",
            "LOGGING: writing to /home/timp/2023_IBG_HAIL/2021_IBG_Hail/hail-20230310-0804-0.2.109-b123465fc0bf.log\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--driver-memory 6G pyspark-shell'\n",
        "\n",
        "import hail as hl\n",
        "hl.plot.output_notebook()\n",
        "hl.init()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5fliBMbtka9"
      },
      "source": [
        "## Read in QC'ed data and PCA scores\n",
        "\n",
        "First, we'll need to read back in the sample annotations and the PCA scores from the previous practical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpikRumotka-"
      },
      "outputs": [],
      "source": [
        "pca_scores = hl.read_table('resources/pca_scores.ht')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tWmsooWtka-",
        "outputId": "d7f166b8-c1ee-4d0b-ac5b-e3086b0fa284"
      },
      "outputs": [
        {
          "ename": "FatalError",
          "evalue": "HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt).\n\nJava stack trace:\nis.hail.utils.HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt).\n\tat is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17)\n\tat is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17)\n\tat is.hail.utils.package$.fatal(package.scala:78)\n\tat is.hail.expr.ir.StringTableReader$.getFileStatuses(StringTableReader.scala:41)\n\tat is.hail.expr.ir.StringTableReader$.apply(StringTableReader.scala:29)\n\tat is.hail.expr.ir.StringTableReader$.fromJValue(StringTableReader.scala:35)\n\tat is.hail.expr.ir.TableReader$.fromJValue(TableIR.scala:113)\n\tat is.hail.expr.ir.IRParser$.table_ir_1(Parser.scala:1582)\n\tat is.hail.expr.ir.IRParser$.$anonfun$table_ir$1(Parser.scala:1553)\n\tat is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)\n\tat is.hail.utils.StackSafe$.run(StackSafe.scala:16)\n\tat is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)\n\tat is.hail.expr.ir.IRParser$.$anonfun$parse_value_ir$1(Parser.scala:2100)\n\tat is.hail.expr.ir.IRParser$.parse(Parser.scala:2096)\n\tat is.hail.expr.ir.IRParser$.parse_value_ir(Parser.scala:2100)\n\tat is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$2(SparkBackend.scala:697)\n\tat is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75)\n\tat is.hail.utils.package$.using(package.scala:635)\n\tat is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75)\n\tat is.hail.utils.package$.using(package.scala:635)\n\tat is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17)\n\tat is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63)\n\tat is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:342)\n\tat is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$1(SparkBackend.scala:696)\n\tat is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)\n\tat is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)\n\tat is.hail.backend.spark.SparkBackend.parse_value_ir(SparkBackend.scala:695)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n\n\nHail version: 0.2.109-b123465fc0bf\nError summary: HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt).",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sa \u001b[38;5;241m=\u001b[39m \u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresources/1kg_annotations.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mimpute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSample\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m<decorator-gen-1442>:2\u001b[0m, in \u001b[0;36mimport_table\u001b[0;34m(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz, filter, find_replace, force, source_file_field)\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/typecheck/check.py:577\u001b[0m, in \u001b[0;36m_make_dec.<locals>.wrapper\u001b[0;34m(__original_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(__original_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    576\u001b[0m     args_, kwargs_ \u001b[38;5;241m=\u001b[39m check_all(__original_func, args, kwargs, checkers, is_method\u001b[38;5;241m=\u001b[39mis_method)\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__original_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/methods/impex.py:1686\u001b[0m, in \u001b[0;36mimport_table\u001b[0;34m(paths, key, min_partitions, impute, no_header, comment, delimiter, missing, types, quote, skip_blank_lines, force_bgz, filter, find_replace, force, source_file_field)\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m find_replace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m         ht \u001b[38;5;241m=\u001b[39m ht\u001b[38;5;241m.\u001b[39mannotate(text\u001b[38;5;241m=\u001b[39mht[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;241m*\u001b[39mfind_replace))\n\u001b[0;32m-> 1686\u001b[0m     first_rows \u001b[38;5;241m=\u001b[39m \u001b[43mfirst_row_ht\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mannotate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_row_ht\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtstr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m FatalError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1691\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_filter_partitions: no partition with index 0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m err\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
            "File \u001b[0;32m<decorator-gen-1120>:2\u001b[0m, in \u001b[0;36mcollect\u001b[0;34m(self, _localize, _timed)\u001b[0m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/typecheck/check.py:577\u001b[0m, in \u001b[0;36m_make_dec.<locals>.wrapper\u001b[0;34m(__original_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[38;5;129m@decorator\u001b[39m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(__original_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    576\u001b[0m     args_, kwargs_ \u001b[38;5;241m=\u001b[39m check_all(__original_func, args, kwargs, checkers, is_method\u001b[38;5;241m=\u001b[39mis_method)\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__original_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/table.py:2128\u001b[0m, in \u001b[0;36mTable.collect\u001b[0;34m(self, _localize, _timed)\u001b[0m\n\u001b[1;32m   2126\u001b[0m e \u001b[38;5;241m=\u001b[39m construct_expr(rows_ir, hl\u001b[38;5;241m.\u001b[39mtarray(t\u001b[38;5;241m.\u001b[39mrow\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m   2127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _localize:\n\u001b[0;32m-> 2128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mEnv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_timed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m e\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/backend/py4j_backend.py:72\u001b[0m, in \u001b[0;36mPy4JBackend.execute\u001b[0;34m(self, ir, timed)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, ir, timed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 72\u001b[0m     jir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_java_value_ir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     stream_codec \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamBufferSpec\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# print(self._hail_package.expr.ir.Pretty.apply(jir, True, -1))\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/backend/py4j_backend.py:164\u001b[0m, in \u001b[0;36mPy4JBackend._to_java_value_ir\u001b[0;34m(self, ir)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_to_java_value_ir\u001b[39m(\u001b[38;5;28mself\u001b[39m, ir):\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_java_ir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_value_ir\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/backend/py4j_backend.py:145\u001b[0m, in \u001b[0;36mPy4JBackend._to_java_ir\u001b[0;34m(self, ir, parse)\u001b[0m\n\u001b[1;32m    143\u001b[0m     r \u001b[38;5;241m=\u001b[39m CSERenderer(stop_at_jir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# FIXME parse should be static\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m     ir\u001b[38;5;241m.\u001b[39m_jir \u001b[38;5;241m=\u001b[39m \u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinalize_randomness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mir_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjirs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ir\u001b[38;5;241m.\u001b[39m_jir\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/backend/py4j_backend.py:149\u001b[0m, in \u001b[0;36mPy4JBackend._parse_value_ir\u001b[0;34m(self, code, ref_map, ir_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_parse_value_ir\u001b[39m(\u001b[38;5;28mself\u001b[39m, code, ref_map\u001b[38;5;241m=\u001b[39m{}, ir_map\u001b[38;5;241m=\u001b[39m{}):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_value_ir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parsable_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mref_map\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mir_map\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
            "File \u001b[0;32m~/.local/lib/python3.9/site-packages/hail/backend/py4j_backend.py:35\u001b[0m, in \u001b[0;36mhandle_java_exception.<locals>.deco\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     tpl \u001b[38;5;241m=\u001b[39m Env\u001b[38;5;241m.\u001b[39mjutils()\u001b[38;5;241m.\u001b[39mhandleForPython(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m     34\u001b[0m     deepest, full, error_id \u001b[38;5;241m=\u001b[39m tpl\u001b[38;5;241m.\u001b[39m_1(), tpl\u001b[38;5;241m.\u001b[39m_2(), tpl\u001b[38;5;241m.\u001b[39m_3()\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m fatal_error_from_java_error_triplet(deepest, full, error_id) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m pyspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mCapturedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m FatalError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mJava stack trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     38\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHail version: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     39\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError summary: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (e\u001b[38;5;241m.\u001b[39mdesc, e\u001b[38;5;241m.\u001b[39mstackTrace, hail\u001b[38;5;241m.\u001b[39m__version__, e\u001b[38;5;241m.\u001b[39mdesc)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
            "\u001b[0;31mFatalError\u001b[0m: HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt).\n\nJava stack trace:\nis.hail.utils.HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt).\n\tat is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17)\n\tat is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17)\n\tat is.hail.utils.package$.fatal(package.scala:78)\n\tat is.hail.expr.ir.StringTableReader$.getFileStatuses(StringTableReader.scala:41)\n\tat is.hail.expr.ir.StringTableReader$.apply(StringTableReader.scala:29)\n\tat is.hail.expr.ir.StringTableReader$.fromJValue(StringTableReader.scala:35)\n\tat is.hail.expr.ir.TableReader$.fromJValue(TableIR.scala:113)\n\tat is.hail.expr.ir.IRParser$.table_ir_1(Parser.scala:1582)\n\tat is.hail.expr.ir.IRParser$.$anonfun$table_ir$1(Parser.scala:1553)\n\tat is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)\n\tat is.hail.utils.StackSafe$.run(StackSafe.scala:16)\n\tat is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)\n\tat is.hail.expr.ir.IRParser$.$anonfun$parse_value_ir$1(Parser.scala:2100)\n\tat is.hail.expr.ir.IRParser$.parse(Parser.scala:2096)\n\tat is.hail.expr.ir.IRParser$.parse_value_ir(Parser.scala:2100)\n\tat is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$2(SparkBackend.scala:697)\n\tat is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75)\n\tat is.hail.utils.package$.using(package.scala:635)\n\tat is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75)\n\tat is.hail.utils.package$.using(package.scala:635)\n\tat is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17)\n\tat is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63)\n\tat is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:342)\n\tat is.hail.backend.spark.SparkBackend.$anonfun$parse_value_ir$1(SparkBackend.scala:696)\n\tat is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)\n\tat is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)\n\tat is.hail.backend.spark.SparkBackend.parse_value_ir(SparkBackend.scala:695)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n\n\n\nHail version: 0.2.109-b123465fc0bf\nError summary: HailException: arguments refer to no files: Vector(resources/1kg_annotations.txt)."
          ]
        }
      ],
      "source": [
        "sa = hl.import_table('resources/1kg_annotations.txt', \n",
        "                     impute=True, \n",
        "                     key='Sample')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC009zG9tka_"
      },
      "source": [
        "Let's randomly throw away some of our population information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKbqsjp1tka_"
      },
      "outputs": [],
      "source": [
        "sa = sa.annotate(\n",
        "    SuperPopulation = hl.if_else(\n",
        "        hl.rand_bool(0.9),\n",
        "        sa.SuperPopulation,\n",
        "        hl.missing(hl.tstr)\n",
        "    )\n",
        ")\n",
        "sa.write('output/censored_1kg_annotations.txt', overwrite=True)\n",
        "sa = hl.read_table('output/censored_1kg_annotations.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWsG_GORtka_"
      },
      "source": [
        "Now, we'll take the first 4 PCs from the PCA table, and add the population information for each sample from our dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5e5p6MXtkbA"
      },
      "outputs": [],
      "source": [
        "ht = pca_scores.select(PC1=pca_scores.scores[0],\n",
        "                       PC2=pca_scores.scores[1],\n",
        "                       PC3=pca_scores.scores[2],\n",
        "                       PC4=pca_scores.scores[3])\n",
        "ht = ht.annotate(pheno = sa[ht.s])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I37LGQVFtkbB"
      },
      "source": [
        "The five populations present in this dataset are `AFR`, `AMR`, `EAS`, `EUR`, and `SAS`. They are three-letter codes from the 1000 Genomes project denoting the [super population of each sample](https://www.internationalgenome.org/category/population/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k08P2faBtkbB"
      },
      "source": [
        "## Visualize!\n",
        "\n",
        "Let's plot all combinations of the first three principal components (PCs) against one another. Perhaps we can identify clear cluster boundaries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUPb-TBEtkbC"
      },
      "outputs": [],
      "source": [
        "import bokeh\n",
        "\n",
        "p12 = hl.plot.scatter(ht.PC1, ht.PC2, xlabel='PC1', ylabel='PC2', label=ht.pheno.SuperPopulation, size=3, width=400, height=400)\n",
        "p13 = hl.plot.scatter(ht.PC1, ht.PC3, xlabel='PC1', ylabel='PC3', label=ht.pheno.SuperPopulation, size=3, width=400, height=400)\n",
        "\n",
        "p23 = hl.plot.scatter(ht.PC2, ht.PC3, xlabel='PC2', ylabel='PC3', label=ht.pheno.SuperPopulation, size=3, width=400, height=400)\n",
        "\n",
        "hl.plot.show(bokeh.layouts.gridplot([[p12],\n",
        "                                     [p13, p23]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzjWCHN2tkbC"
      },
      "source": [
        "## Reidentify samples with missing ancestry based on PCA scores\n",
        "\n",
        "Now that we can see how the populations are decomposed by the PCs, let's try to reidentify the masked samples.\n",
        "\n",
        "First, we'll define a grading scheme to check against the true populations of each masked sample. (The `check` function will see how many masked samples you have correctly identified.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBchVRcitkbC"
      },
      "outputs": [],
      "source": [
        "true_labels = hl.import_table('resources/true_pops.txt', key='s').cache()\n",
        "def check(ht):\n",
        "    ht = ht.annotate(true_pop = true_labels[ht.s].RealSuperPopulation)\n",
        "    c = ht.aggregate(hl.agg.filter(hl.is_missing(ht.pheno.SuperPopulation), \n",
        "                                   hl.agg.counter((ht.unmasked, ht.true_pop))))\n",
        "    n_correct = sum(count for k, count in c.items() if k[0] == k[1])\n",
        "    n_wrong = sum(count for k, count in c.items() if k[0] != k[1])\n",
        "    print(f'Correctly identified {n_correct} / {n_correct + n_wrong} masked samples.')\n",
        "    print()\n",
        "    \n",
        "    for (unm, true), n in c.items():\n",
        "        if unm != true:\n",
        "            if unm is not None:\n",
        "                print(f'Incorrectly assigned {n} {true} samples as {unm}.')\n",
        "            else:\n",
        "                print(f'Left {n} {true} samples unassigned.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MshfUlM1tkbC"
      },
      "source": [
        "## Fill in the below\n",
        "\n",
        "Your job is to expand the below code to reidentify the population labels. One of the populations has already been provided as an example.\n",
        "\n",
        "### `case().when()` in Hail\n",
        "\n",
        "The `case` / `when` / `default` motif you see below is a nice way to write `if` / `else if` / `else`. The returned `unmasked` will be equal to the result of the first `when` whose predicate is `True`.\n",
        "\n",
        "### A note on `&` and `|`\n",
        "\n",
        "Python uses `and` and `or` for logical operators. Hail expressions use `&` for 'and' and `|` for or.\n",
        "\n",
        "This can lead to some confusion, especially since `&` and `|` often don't play nicely with expressions involving `>`, `<`, `==`, or `!=`. If both of these operators appear, you will need to wrap the comparison in parentheses.\n",
        "\n",
        "Suppose we want to write code that returns true when \"PC1 is greater than 0.1 or PC2 is less than 0.2\":\n",
        "\n",
        "**correct**:\n",
        "\n",
        "```\n",
        "(ht.PC1 > 0.1) | (ht.PC2 < 0.2)\n",
        "```\n",
        "\n",
        "**incorrect**:\n",
        "```\n",
        "ht.PC1 > 0.1 or ht.PC2 < 0.2\n",
        "ht.PC1 > 0.1 | ht.PC2 < 0.2\n",
        "(ht.PC1 > 0.1) or (ht.PC2 < 0.2)\n",
        "```\n",
        "\n",
        "### `hl.all` and `hl.any`\n",
        "\n",
        "You might also find it easier to use `hl.all` (which is \"and\") and `hl.any` (which is \"or\"). For example, this\n",
        "\n",
        "```\n",
        "(ht.PC1 > 0.1) | (ht.PC2 < 0.2) | (ht.PC3 >= 0.1)\n",
        "```\n",
        "\n",
        "could also be written as\n",
        "\n",
        "```\n",
        "hl.any(ht.PC1 > 0.1,\n",
        "       ht.PC2 < 0.2,\n",
        "       ht.PC3 >= 0.1)\n",
        "```\n",
        "\n",
        "### To think about\n",
        "\n",
        "Which population is hardest to reidentify? Why?\n",
        "\n",
        "### Extras\n",
        "\n",
        "Try plotting the PCs again with the re-identified population labels.\n",
        "\n",
        "Try plotting the PCs again, highlighting the ones that you missed. (The true population labels are in the table `true_labels`.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C49KZRmjtkbD"
      },
      "outputs": [],
      "source": [
        "unmasked = ht.annotate(\n",
        "    unmasked = hl.case()\n",
        "        .when((ht.PC2 > 0.2) & (ht.PC2 > 0.2), 'EAS')\n",
        "#         .when(..., 'AFR')\n",
        "#         .when(..., 'AMR')\n",
        "#         .when(..., 'EUR')\n",
        "#         .when(..., 'SAS')\n",
        "        .default(ht.pheno.SuperPopulation)\n",
        ")\n",
        "check(unmasked)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWkNtd3jtkbD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}